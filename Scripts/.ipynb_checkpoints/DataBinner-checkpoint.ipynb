{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data binner\n",
    "#### For FERMI data from Oct/Nov 2017 at DiProI beamline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Info\n",
    "\n",
    "This script works on the HDF5 files created by the Data collector (16_data_collection.ipynb) that end on '_col.h5' and are located in the 'combined' folder of each run.\n",
    "\n",
    "The script has two main functionailities:\n",
    "1. Apply filters to the data on a shot-to-shot basis with respect to e.g. incident intensity, photon energy bandwidth, ...\n",
    "2. Bin the data along incident phton energy and pump-probe delay. For the incident photon energy binnig is performed based on the actual central photon energy of each shot.\n",
    "\n",
    "Uses:\n",
    "- /src/data_tools_v2.py\n",
    "- /src/fit_tools.py\n",
    "\n",
    "\n",
    "-----------------------\n",
    "Created by Simon Schreck (simon.schreck@fysik.su.se) in Dec 2017 - Jan 2018 - with some parts beeing courtousy of Fivos Perakis.\n",
    "\n",
    "Last updated: April 2018, by Simon Schreck (simon.schreck@fysik.su.se)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization\n",
    "#### Load packages and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import h5py\n",
    "import sys\n",
    "import time\n",
    "import scipy.stats\n",
    "import os.path\n",
    "from importlib import reload\n",
    "\n",
    "sys.path.insert(0, '../src/')\n",
    "\n",
    "import data_tools_v2\n",
    "reload(data_tools_v2)\n",
    "\n",
    "import fit_tools\n",
    "reload(fit_tools)\n",
    "\n",
    "#from data_tools_v2 import * as dt\n",
    "import data_tools_v2 as dt\n",
    "from fit_tools import *\n",
    "\n",
    "# Ignore Runtime Warnings for divide and invalid values\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "\n",
    "##########################################\n",
    "### DEFINE WHERE FIGURES ARE DISPLAYED ###\n",
    "##########################################\n",
    "# After changing this the kernel needs to be restarted\n",
    "# Plot figures in in external windows (may need to set up your python environment properly for this to work)\n",
    "#%matplotlib qt\n",
    "# Plot figures inline in notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "### XAS DATA SOURCE ###\n",
    "#######################\n",
    "# Define which data are used for the XAS intensity\n",
    "# Possible values:\n",
    "# 'xas_img_int'    - Integrated intensity of the XAS image as calculated in data collection\n",
    "# 'xas_daq_int'    - Integrated intensity of the XAS image as saved by DiProI DAQ\n",
    "# 'xas_img_blobs'  - Number of blobs in XAS image (DO NOT USE (YET)\n",
    "\n",
    "# 'xes_img_int'    - Integrated intensity of the XES image as calculated in data collection\n",
    "# 'xes_daq_int'    - Integrated intensity of the XES image as saved by DiProI DAQ\n",
    "# 'xes_img_blobs'  - Number of blobs in XES image (DO NOT USE (YET)\n",
    "\n",
    "XAS_source = 'xas_img_int'\n",
    "\n",
    "#########################\n",
    "### SHOW HISTOGRAMS ? ###\n",
    "#########################\n",
    "show_histograms = True\n",
    "# Number of bins\n",
    "n_bin_i0      = 40\n",
    "n_bin_centers = 40\n",
    "n_bin_widths  = 40\n",
    "n_bin_xas     = 40\n",
    "\n",
    "\n",
    "#######################\n",
    "### FILTER SETTINGS ###\n",
    "#######################\n",
    "\n",
    "# Incident intensity\n",
    "filter_i0  = True \n",
    "i0_low_thr = 2e5\n",
    "i0_hi_thr  = np.inf\n",
    "\n",
    "# Incident photon energy bandwidth\n",
    "filter_width  = True\n",
    "width_low_thr = 0\n",
    "width_hi_thr  = 0.8\n",
    "\n",
    "# Incident photon energy position\n",
    "filter_center  = False\n",
    "center_low_thr = -np.inf\n",
    "center_hi_thr  =  np.inf\n",
    "\n",
    "# XAS intensity\n",
    "filter_xas  = True\n",
    "xas_low_thr = 1000\n",
    "xas_hi_thr  = np.inf\n",
    "\n",
    "# Mass spec count rate\n",
    "filter_ms     = False\n",
    "ms_low_thr    = 0\n",
    "ms_hi_thr     = np.inf\n",
    "\n",
    "##########################\n",
    "### BINNING PARAMETERS ###\n",
    "##########################\n",
    "\n",
    "###### Incident photon energy ######\n",
    "E_bin_type  = 'auto' # 'auto' or 'manual'\n",
    "# If E_bin_type is 'auto' use:\n",
    "E_bin_width = 0.25\n",
    "# If E_bin_type is 'manual' use:\n",
    "E_bin_edges_man = np.array([281.6, 282.0, 282.4, 282.8, 283.2, 283.6, 284.0, 284.4, 284.8, 285.2, 285.6, 286.0, 286.4])\n",
    "E_bin_edges_man = np.array([280, 290.0])\n",
    "\n",
    "\n",
    "######### Delay #####################\n",
    "delay_bin_type   = 'auto' # 'auto' or 'manual'\n",
    "# If delay_bin_type is 'auto' the delay values that were set during data aquisition are used as bin centers\n",
    "\n",
    "# If delay_bin_type is 'manual' define unit and bin EDGES (!!!) here:\n",
    "delay_bin_unit   = 'ps'     # 'mm' or 'ps'\n",
    "delays_edges_man = np.array([-1, 0, 0.5, 1.0, 1.5, 5, 15, 310])\n",
    "\n",
    "\n",
    "#################\n",
    "### TIME ZERO ###\n",
    "#################\n",
    "def getTimeZero(runs, run_type, bt) :\n",
    "    \n",
    "    if bt == 2 :\n",
    "        if (runs[0] in np.arange(0, 23+1)) and (run_type == 'XAS') :\n",
    "            TimeZero = 141.654\n",
    "        elif (runs[0] in [27, 28, 29]) and (run_type == 'XAS') :\n",
    "            TimeZero = 141.530\n",
    "        elif (runs[0] in [13, 14, 15, 16]) and (run_type == 'XES') :\n",
    "            TimeZero = 141.530\n",
    "        else :\n",
    "            TimeZero = 141.654\n",
    "    if bt == 1 :\n",
    "        TimeZero = 136.376\n",
    "\n",
    "    return TimeZero\n",
    "\n",
    "#################\n",
    "### XES STUFF ###\n",
    "#################\n",
    "\n",
    "# Should the XES spectra be binned? True/False\n",
    "bin_xes_specs = True\n",
    "\n",
    "# XES emission energy rebinning (1 pixel ~ 60 meV) \n",
    "xes_rebinning = 5 # 5 --> ~300 meV emission energy steps\n",
    "\n",
    "# Provide filenames of dispersion of XES detector \n",
    "def getDisp(BT) :\n",
    "    if BT == 1 :\n",
    "        xes_disp = 'XAS021_disp.h5'\n",
    "    elif BT == 2 :\n",
    "        xes_disp = 'XAS035_disp.h5'\n",
    "    else :\n",
    "        raise NameError('BT mus be 1 or 2')\n",
    "    return xes_disp\n",
    "\n",
    "##############\n",
    "### UNUSED ###\n",
    "##############\n",
    "bin_xes_blobs = False # DO NOT CHANGE THIS!!! \n",
    "disp_pixels   = 1625  # DO NOT CHANGE THIS!!! \n",
    "# BT 2\n",
    "#xes_curv_file = 'XES001_NoPump_curv.h5'\n",
    "# BT 1\n",
    "xes_curv_file = 'XAS002_curv.h5'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do the Data Binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Reload data and fit tools\n",
    "import data_tools_v2\n",
    "reload(data_tools_v2)\n",
    "\n",
    "import fit_tools\n",
    "reload(fit_tools)\n",
    "\n",
    "import data_tools_v2 as dt\n",
    "from fit_tools import *\n",
    "\n",
    "### --- START OF DEFINITION WHICH DATA TO BIN --- ###\n",
    "\n",
    "##############################\n",
    "### DEFINE THE RUN(S) ########\n",
    "##############################\n",
    "\n",
    "runs = [14,18,19,20]\n",
    "\n",
    "run_type = 'XAS' # 'XAS' or 'XES'\n",
    "\n",
    "##############################\n",
    "### DEFINE THE BEAMTIME ######\n",
    "##############################\n",
    "BT = 2 # 1: 1st beamtime, 2: 2nd beamtime\n",
    "\n",
    "##############################\n",
    "### DEFINE THE DATA PATH #####\n",
    "##############################\n",
    "if(BT==1):\n",
    "    data_path = 'D:/FERMI 2017 1/'\n",
    "else:\n",
    "    data_path = 'D:/FERMI 2017 2/'\n",
    "\n",
    "### --- END OF DEFINITION WHICH DATA TO BIN --- ###\n",
    "\n",
    "\n",
    "### --- START OF MAIN SCRIPT --- ###\n",
    "\n",
    "# Check that data path exists\n",
    "if not os.path.exists(data_path) :\n",
    "    raise NameError('Check data_path! It does not exist!')\n",
    "\n",
    "# Check that all runs exist\n",
    "i = 0\n",
    "while i < len(runs) :\n",
    "    # Create the path to the run folder\n",
    "    run_path = dt.do_runpath(runs[i], run_type, BT, data_path)\n",
    "    \n",
    "    if not os.path.exists(run_path) :\n",
    "        print('Run %d does not exist! Skipping this run!'%runs[i])\n",
    "        runs = np.delete(runs, i)\n",
    "    else :\n",
    "        i = i + 1\n",
    "        \n",
    "print('Start binning runs:')\n",
    "print(runs)\n",
    "\n",
    "# Get TimeZero\n",
    "TimeZero = getTimeZero(runs, run_type, BT)\n",
    "\n",
    "# Start timer\n",
    "t = time.time()\n",
    "\n",
    "# Reset some boleans\n",
    "ms_missing = xes_missing = xes_spec_missing = False\n",
    "\n",
    "# Define empty arrays to collect data in\n",
    "bunch_id_all         = []\n",
    "xas_int_all          = []\n",
    "xas_tfy_all          = []\n",
    "xas_tfy_blobsnum_all = []\n",
    "xes_blobs_x_all      = []\n",
    "xes_blobs_y_all      = []\n",
    "xes_blobsnum_all     = []\n",
    "xes_int_all          = []\n",
    "xes_spec_all         = []\n",
    "delay_pos_all        = []\n",
    "laser_int_all        = []\n",
    "ms_tof_all           = []\n",
    "ms_counts_all        = []\n",
    "\n",
    "i0_all               = []\n",
    "Gauss_amps_all       = []\n",
    "Gauss_centers_all    = []\n",
    "Gauss_widths_all     = []\n",
    "\n",
    "# Loop over runs to load the data\n",
    "for run in runs :\n",
    "    # Create the path to the RUN folder\n",
    "    run_path = dt.do_runpath(run, run_type, BT, data_path)\n",
    "    print('\\n---Messages, Run %d:'%run)\n",
    "    \n",
    "    # Path to data in this folder\n",
    "    load_path = run_path+'/combined/'\n",
    "    \n",
    "    # Get file names of 'collected' files\n",
    "    tmp,file_names = dt.discover_files(load_path)\n",
    "    \n",
    "    ###########################\n",
    "    ### CHECK IF DATA EXIST ###\n",
    "    ###########################    \n",
    "    \n",
    "    \n",
    "    \n",
    "    fh5_check = h5py.File(load_path+file_names[0], 'r')\n",
    "    \n",
    "    if not '/MASSSPEC/counts' in fh5_check :\n",
    "        if filter_ms :\n",
    "            print('Mass Spec data are missing for run %d.'%run)\n",
    "            print('Turning Mass Spec filtering OFF!')\n",
    "        ms_missing = True\n",
    "    \n",
    "    if not '/XES/xes_blobsnum' in fh5_check:\n",
    "    #    print('XES blobs are missing for run %d.'%run)\n",
    "    #    print('Turning XES filtering and binning OFF!')\n",
    "        xes_missing = True\n",
    "        \n",
    "    if not '/XES/xes_spec' in fh5_check:\n",
    "        xes_spec_missing = True\n",
    "        \n",
    "    fh5_check.close()\n",
    "        \n",
    "    ########################\n",
    "    ### LOAD THE DATA ######\n",
    "    ########################\n",
    "    # Loop over collected files\n",
    "    for j in range(len(file_names)):\n",
    "        \n",
    "        fh5 = h5py.File(load_path+file_names[j], 'r')\n",
    "        \n",
    "        #print(file_names[j])\n",
    "        # Bunch ID\n",
    "        bunch_id = fh5['/bunch_id'].value\n",
    "        bunch_id_all.extend(bunch_id)\n",
    "        \n",
    "        if XAS_source == 'xas_img_int' :\n",
    "            # Use integrated image intensity\n",
    "            xas_int = fh5['/XAS/xas_tfy'].value\n",
    "            xas_int_all.extend(xas_int)\n",
    "        elif XAS_source == 'xas_img_blobs' :\n",
    "            # Use number of blobs in image\n",
    "            xas_int = fh5['/XAS/xas_tfy_blobsnum'].value\n",
    "            xas_int_all.extend(xas_int)\n",
    "        elif XAS_source == 'xas_daq_int' :\n",
    "            # Use integrated intensity provided by daq\n",
    "            xas_int = fh5['/XAS/xas_int'].value\n",
    "            xas_int_all.extend(xas_int)\n",
    "        elif XAS_source == 'xes_img_int' :\n",
    "            # Use integrated image intensity\n",
    "            xas_int = fh5['/XES/xes_pfy'].value\n",
    "            xas_int_all.extend(xas_int)\n",
    "        elif XAS_source == 'xes_img_blobs' :\n",
    "            # Use number of blobs in image\n",
    "            xas_int = fh5['/XES/xes_blobsnum'].value\n",
    "            xas_int_all.extend(xas_int)\n",
    "        elif XAS_source == 'xes_daq_int' :\n",
    "            # Use integrated intensity provided by daq\n",
    "            xas_int = fh5['/XES/xes_int'].value\n",
    "            xas_int_all.extend(xas_int)            \n",
    "        else :\n",
    "            raise NameError('XAS_source %s is not a valid source!'%XAS_source)\n",
    "\n",
    "        # Delay\n",
    "        delay_pos = fh5['/LASER/delay_pos'].value\n",
    "        delay_pos_all.extend(delay_pos)\n",
    "        \n",
    "        # I0\n",
    "        i0 = fh5['/FEL/i0'].value\n",
    "        i0_all.extend(i0)\n",
    "        \n",
    "        # Gauss amps\n",
    "        Gauss_amps = fh5['/FEL/Gauss_amps'].value\n",
    "        Gauss_amps_all.extend(Gauss_amps)\n",
    "        \n",
    "        # Gauss centers\n",
    "        Gauss_centers = fh5['/FEL/Gauss_centers'].value\n",
    "        Gauss_centers_all.extend(Gauss_centers)\n",
    "        \n",
    "        # Gauss widths\n",
    "        Gauss_widths = fh5['/FEL/Gauss_widths'].value\n",
    "        Gauss_widths_all.extend(Gauss_widths)\n",
    "        \n",
    "        # MS counts\n",
    "        if not ms_missing :\n",
    "            ms_counts = fh5['/MASSSPEC/counts'].value\n",
    "            ms_counts_all.extend(ms_counts)\n",
    "            \n",
    "        # XES\n",
    "        if not xes_missing and bin_xes_blobs:\n",
    "            xes_blobsnum = fh5['/XES/xes_blobsnum'].value\n",
    "            xes_blobsnum_all.extend(xes_blobsnum)\n",
    "            xes_blobs_x = fh5['/XES/xes_blobs_x'].value\n",
    "            xes_blobs_x_all.extend(xes_blobs_x)\n",
    "            xes_blobs_y = fh5['/XES/xes_blobs_y'].value\n",
    "            xes_blobs_y_all.extend(xes_blobs_y)\n",
    "            \n",
    "        if not xes_spec_missing :\n",
    "            xes_spec = fh5['/XES/xes_spec'].value\n",
    "            xes_spec_all.extend(xes_spec)\n",
    "            \n",
    "bunch_id_all         = np.array(bunch_id_all)\n",
    "xas_int_all          = np.array(xas_int_all)\n",
    "delay_pos_all        = np.array(delay_pos_all)\n",
    "i0_all               = np.array(i0_all)\n",
    "Gauss_amps_all       = np.array(Gauss_amps_all)\n",
    "Gauss_centers_all    = np.array(Gauss_centers_all)\n",
    "Gauss_widths_all     = np.array(Gauss_widths_all)\n",
    "ms_counts_all        = np.array(ms_counts_all)\n",
    "xes_blobsnum_all     = np.array(xes_blobsnum_all)\n",
    "xes_blobs_x_all      = np.array(xes_blobs_x_all)\n",
    "xes_blobs_y_all      = np.array(xes_blobs_y_all)\n",
    "xes_spec_all         = np.array(xes_spec_all)\n",
    "\n",
    "xes_spec_length = len(xes_spec_all)/len(bunch_id_all)\n",
    "\n",
    "# Take out all shots wehere FEL spectrum fit failed, i.e. where fit parameters are NaN (to not have runtime warning later)\n",
    "nan_mask     = ~np.isnan(Gauss_widths_all)\n",
    "if not xes_missing and bin_xes_blobs:\n",
    "    nan_mask_xes = np.repeat(nan_mask, xes_blobsnum_all)\n",
    "if not xes_spec_missing :\n",
    "    nan_mask_xes_spec = np.repeat(nan_mask, xes_spec_length)\n",
    "    \n",
    "bunch_id_all         = bunch_id_all[nan_mask]\n",
    "xas_int_all          = xas_int_all[nan_mask]\n",
    "delay_pos_all        = delay_pos_all[nan_mask]\n",
    "i0_all               = i0_all[nan_mask]\n",
    "Gauss_amps_all       = Gauss_amps_all[nan_mask]\n",
    "Gauss_centers_all    = Gauss_centers_all[nan_mask]\n",
    "Gauss_widths_all     = Gauss_widths_all[nan_mask]\n",
    "if not ms_missing :\n",
    "    ms_counts_all        = ms_counts_all[nan_mask]\n",
    "if not xes_missing and bin_xes_blobs:\n",
    "    xes_blobsnum_all     = xes_blobsnum_all[nan_mask]\n",
    "    xes_blobs_x_all      = xes_blobs_x_all[nan_mask_xes]\n",
    "    xes_blobs_y_all      = xes_blobs_y_all[nan_mask_xes]\n",
    "if not xes_spec_missing and bin_xes_specs:\n",
    "    xes_spec_all         = xes_spec_all[nan_mask_xes_spec]\n",
    "    \n",
    "########################\n",
    "### FILTER THE DATA ####\n",
    "########################\n",
    "print('\\n---Filtering...')\n",
    "# Build the filter matrix\n",
    "filter_matrix = []\n",
    "\n",
    "filter_matrix.append(delay_pos_all!=0)\n",
    "\n",
    "# Filter on I0\n",
    "if filter_i0 :\n",
    "    print('... on I0 (%2.1e, %2.1e)'%(i0_low_thr, i0_hi_thr))\n",
    "    filter_matrix.append(i0_all>=i0_low_thr)\n",
    "    filter_matrix.append(i0_all<=i0_hi_thr)\n",
    "\n",
    "# Filter on FEL bandwith\n",
    "if filter_width :\n",
    "    print('... on FEL bandwidth (%3.2f, %3.2f)' %(width_low_thr, width_hi_thr))\n",
    "    filter_matrix.append(Gauss_widths_all>=width_low_thr)\n",
    "    filter_matrix.append(Gauss_widths_all<=width_hi_thr)\n",
    "    \n",
    "# Filter on FEL center energy\n",
    "if filter_center :\n",
    "    print('... on FEL center energy (%3.2f, %3.2f)' %(center_low_thr, center_hi_thr))\n",
    "    filter_matrix.append(Gauss_centers_all>=center_low_thr)\n",
    "    filter_matrix.append(Gauss_centers_all<=center_hi_thr)\n",
    "    \n",
    "# Filter on XAS intensity\n",
    "if filter_xas :\n",
    "    print('... on XAS intensity (%3.2f, %3.2f)' %(xas_low_thr, xas_hi_thr))\n",
    "    filter_matrix.append(xas_int_all>=xas_low_thr)\n",
    "    filter_matrix.append(xas_int_all<=xas_hi_thr)\n",
    "\n",
    "# Filter on MS counts\n",
    "if filter_ms and not ms_missing:\n",
    "    print('... on MASS SPEC counts')\n",
    "    filter_matrix.append(ms_counts_all>=ms_low_thr)\n",
    "    filter_matrix.append(ms_counts_all<=ms_hi_thr)\n",
    "    \n",
    "good_shots_mask = np.all(filter_matrix, axis=0)\n",
    "if not xes_missing and bin_xes_blobs:\n",
    "    good_shots_mask_xes = np.repeat(good_shots_mask, xes_blobsnum_all)\n",
    "if not xes_spec_missing and bin_xes_specs:\n",
    "    good_shots_mask_xes_spec = np.repeat(good_shots_mask, xes_spec_length)\n",
    "\n",
    "# Apply the filter\n",
    "bunch_id_good         = bunch_id_all[good_shots_mask]\n",
    "xas_int_good          = xas_int_all[good_shots_mask]\n",
    "delay_pos_good        = delay_pos_all[good_shots_mask]\n",
    "i0_good               = i0_all[good_shots_mask]\n",
    "Gauss_amps_good       = Gauss_amps_all[good_shots_mask]\n",
    "Gauss_centers_good    = Gauss_centers_all[good_shots_mask]\n",
    "Gauss_widths_good     = Gauss_widths_all[good_shots_mask]\n",
    "if not ms_missing :\n",
    "    ms_counts_good        = ms_counts_all[good_shots_mask]\n",
    "if not xes_missing and bin_xes_blobs:\n",
    "    xes_blobsnum_good     = xes_blobsnum_all[good_shots_mask]\n",
    "    xes_blobs_x_good      = xes_blobs_x_all[good_shots_mask_xes]\n",
    "    xes_blobs_y_good      = xes_blobs_y_all[good_shots_mask_xes]\n",
    "if not xes_spec_missing and bin_xes_specs:\n",
    "    xes_spec_good         = xes_spec_all[good_shots_mask_xes_spec]\n",
    "\n",
    "print('Total number of ALL shots: %d' %(len(bunch_id_all)))\n",
    "print('Filtered out %3.2f percent of all the shots' %(100*(len(bunch_id_all)-len(bunch_id_good))/len(bunch_id_all)))\n",
    "print('Total number of GOOD shots: %d' %(len(bunch_id_good)))\n",
    "\n",
    "########################\n",
    "### Plot Histrograms ###\n",
    "########################\n",
    "if show_histograms :\n",
    "    plt.figure(figsize = [14, 4])\n",
    "    \n",
    "    plt.suptitle('Histograms', fontsize = 14)\n",
    "    \n",
    "    # I0\n",
    "    plt.subplot(141)\n",
    "    i0_bins = np.arange(np.min(i0_all), np.max(i0_all), (np.max(i0_all) - np.min(i0_all)) / n_bin_i0)\n",
    "    plt.hist(i0_all, bins = i0_bins, label = 'All shots') \n",
    "    plt.hist(i0_good, bins = i0_bins, label = 'Good shots')\n",
    "    plt.ylabel('Number of Shots')\n",
    "    plt.xlabel('I0 (arb. u.)')\n",
    "    #plt.title('Incident intensity I0')\n",
    "    plt.legend(loc = 0, fontsize = 9)\n",
    "    \n",
    "    # Gauss_centers\n",
    "    plt.subplot(142)\n",
    "    Gauss_centers_bins = np.arange(np.min(Gauss_centers_all), np.max(Gauss_centers_all), (np.max(Gauss_centers_all) - np.min(Gauss_centers_all)) / n_bin_centers)\n",
    "    plt.hist(Gauss_centers_all, bins = Gauss_centers_bins, label = 'All shots') \n",
    "    plt.hist(Gauss_centers_good, bins = Gauss_centers_bins, label = 'Good shots')\n",
    "    plt.ylabel('Number of Shots')\n",
    "    plt.xlabel('Gauss Center (eV)')\n",
    "    #plt.title('Incident photon energy Gauss_centers')\n",
    "    plt.legend(loc = 0, fontsize = 9)\n",
    "    \n",
    "    # Gauss_widths\n",
    "    plt.subplot(143)\n",
    "    #Gauss_widths_bins = np.arange(np.min(Gauss_widths_all), np.max(Gauss_widths_all), (np.max(Gauss_widths_all) - np.min(Gauss_widths_all)) / n_bin_widths)\n",
    "    Gauss_widths_bins = np.arange(0, 1.5, 1.5/n_bin_widths)\n",
    "    plt.hist(Gauss_widths_all, bins = Gauss_widths_bins, label = 'All shots') \n",
    "    plt.hist(Gauss_widths_good, bins = Gauss_widths_bins, label = 'Good shots')\n",
    "    plt.ylabel('Number of Shots')\n",
    "    plt.xlabel('Gauss Width (eV)')\n",
    "    #plt.title('Incident bandwidth Gauss_widths')\n",
    "    plt.xlim([0, 1.5])\n",
    "    plt.legend(loc = 0, fontsize = 9)\n",
    "    \n",
    "    # xas_int\n",
    "    plt.subplot(144)\n",
    "    xas_int_bins = np.arange(np.min(xas_int_all), np.max(xas_int_all), (np.max(xas_int_all) - np.min(xas_int_all)) / n_bin_xas)\n",
    "    plt.hist(xas_int_all, bins = xas_int_bins, label = 'All shots') \n",
    "    plt.hist(xas_int_good, bins = xas_int_bins, label = 'Good shots')\n",
    "    plt.ylabel('Number of Shots')\n",
    "    plt.xlabel('XAS intensity (arb. u.)')\n",
    "    #plt.title('XAS intensity')\n",
    "    plt.legend(loc = 0, fontsize = 9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "\n",
    "#####################\n",
    "### BIN THE DATA ####\n",
    "#####################\n",
    "# Create DELAY axis and DELAY bin edges\n",
    "if delay_bin_type == 'auto' :\n",
    "    delays_mm, n_shots_delay = np.unique(delay_pos_good, return_counts=True)\n",
    "\n",
    "    if not len(delays_mm) == 1 :\n",
    "        delays_mm_edges = (delays_mm[1:] + delays_mm[:-1]) / 2\n",
    "        delays_mm_edges = np.insert(delays_mm_edges, 0, delays_mm[0] - 0.5*(delays_mm[1]-delays_mm[0]))\n",
    "        delays_mm_edges = np.append(delays_mm_edges, delays_mm[-1] + 0.5*(delays_mm[-1]-delays_mm[-2])) \n",
    "    else :\n",
    "        delays_mm_edges = np.array([delays_mm[0] - 200, delays_mm[0] + 200])\n",
    "\n",
    "    delays_fs       = dt.mm2fs(delays_mm - TimeZero)\n",
    "    delays_fs_edges = dt.mm2fs(delays_mm_edges - TimeZero)\n",
    "\n",
    "elif delay_bin_type == 'manual' :\n",
    "    if delay_bin_unit == 'mm' :\n",
    "        delays_mm_edges = delays_edges_man\n",
    "    elif delay_bin_unit == 'ps' :\n",
    "        delays_mm_edges = dt.fs2mm(delays_edges_man*1e3) + TimeZero\n",
    "        \n",
    "    delays_mm_edges = np.array(delays_mm_edges)\n",
    "        \n",
    "    delays_mm       = (delays_mm_edges[1:] + delays_mm_edges[:-1]) / 2\n",
    "    delays_fs       = dt.mm2fs(delays_mm - TimeZero)\n",
    "    delays_fs_edges = dt.mm2fs(delays_mm_edges - TimeZero)\n",
    "\n",
    "\n",
    "# Create PHOTON ENERGY axis and PHOTON ENERGY bin edges\n",
    "if E_bin_type == 'auto' :\n",
    "    E_bin_min = np.floor(np.min(Gauss_centers_good)/E_bin_width)*E_bin_width\n",
    "    E_bin_max = np.ceil(np.max(Gauss_centers_good)/E_bin_width)*E_bin_width\n",
    "\n",
    "    bin_num = (E_bin_max - E_bin_min) / E_bin_width\n",
    "\n",
    "    E_bin_edges   = np.linspace(E_bin_min, E_bin_max, num = np.int(bin_num)+1)\n",
    "elif E_bin_type == 'manual' :\n",
    "    E_bin_edges = np.array(E_bin_edges_man, dtype=float)\n",
    "else :\n",
    "    raise NameError('E_bin_type must be auto or manual')\n",
    "\n",
    "E_bin_centers = (E_bin_edges[1:] + E_bin_edges[:-1]) / 2\n",
    "\n",
    "# Print(delay and hv bin edges)\n",
    "print('\\n')\n",
    "print('Delay bin edges and centers in mm:')\n",
    "print(delays_mm_edges)\n",
    "print(delays_mm)\n",
    "print('Delay bin edges and centers in ps:')\n",
    "print(delays_fs_edges*1e-3)\n",
    "print(delays_fs*1e-3)\n",
    "print('Photon energy bin edges and centers in eV')\n",
    "print(E_bin_edges)\n",
    "print(E_bin_centers)\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "### XAS BINNING ###\n",
    "# Make 2d (delay_mm vs hv_inc) histograms for TFY intensity, I0, num of shots and XAS = TFY / I0\n",
    "hist_tfy,   xed, yed = np.histogram2d(delay_pos_good, Gauss_centers_good, bins=[delays_mm_edges, E_bin_edges], weights = xas_int_good)\n",
    "hist_i0,    xed, yed = np.histogram2d(delay_pos_good, Gauss_centers_good, bins=[delays_mm_edges, E_bin_edges], weights = i0_good)\n",
    "hist_shots, xed, yed = np.histogram2d(delay_pos_good, Gauss_centers_good, bins=[delays_mm_edges, E_bin_edges])\n",
    "hist_xas,   xed, yed = np.histogram2d(delay_pos_good, Gauss_centers_good, bins=[delays_mm_edges, E_bin_edges], weights = xas_int_good/i0_good)\n",
    "\n",
    "# Get the standard deviation for each bin in the above 2d histograms\n",
    "std_tfy_a = scipy.stats.binned_statistic_2d(delay_pos_good, Gauss_centers_good, xas_int_good,         np.std, bins=[delays_mm_edges, E_bin_edges])\n",
    "std_i0_a  = scipy.stats.binned_statistic_2d(delay_pos_good, Gauss_centers_good, i0_good,              np.std, bins=[delays_mm_edges, E_bin_edges])\n",
    "std_xas_a = scipy.stats.binned_statistic_2d(delay_pos_good, Gauss_centers_good, xas_int_good/i0_good, np.std, bins=[delays_mm_edges, E_bin_edges])\n",
    "\n",
    "std_tfy   = std_tfy_a.statistic\n",
    "std_i0    = std_i0_a.statistic\n",
    "std_xas   = std_xas_a.statistic\n",
    "\n",
    "# Calculate the standard error for each bin in the above 2d histograms\n",
    "hist_tfy_err = std_tfy / np.sqrt(hist_shots)\n",
    "hist_i0_err  = std_i0 / np.sqrt(hist_shots)\n",
    "hist_xas_err = std_xas / np.sqrt(hist_shots)\n",
    "\n",
    "# Normalize the 2d histograms by number of shots in each bin\n",
    "XAS_2dmatrix   = hist_xas / hist_shots\n",
    "TFY_2dmatrix   = hist_tfy / hist_shots\n",
    "i0_2dmatrix    = hist_i0  / hist_shots\n",
    "\n",
    "# Rename shots histogram and error histograms (just for consistency)\n",
    "Shots_2dmatrix = hist_shots\n",
    "\n",
    "XAS_2dmatrix_err   = hist_xas_err\n",
    "TFY_2dmatrix_err   = hist_tfy_err\n",
    "i0_2dmatrix_err    = hist_i0_err\n",
    "\n",
    "# Calculate XAS intensity as TFY divided by I0 after binning (v2)\n",
    "XAS_2dmatrix_v2   = hist_tfy/hist_i0\n",
    "\n",
    "# Get projections onto hv and delay axis\n",
    "XAS_hv_all     = np.nansum(XAS_2dmatrix, axis = 0) / np.sum(~np.isnan(XAS_2dmatrix), axis = 0)\n",
    "XAS_delay_all  = np.nansum(XAS_2dmatrix, axis = 1) / np.sum(~np.isnan(XAS_2dmatrix), axis = 1)\n",
    "    \n",
    "XAS_hv_all_err    = np.nansum(XAS_2dmatrix_err, axis = 0) / np.sum(~np.isnan(XAS_2dmatrix_err), axis = 0)\n",
    "XAS_delay_all_err = np.nansum(XAS_2dmatrix_err, axis = 1) / np.sum(~np.isnan(XAS_2dmatrix_err), axis = 1)\n",
    "\n",
    "\n",
    "#plt.figure()\n",
    "#plt.plot(E_bin_centers, XAS_hv_all, label = 'normal')\n",
    "#plt.plot(E_bin_centers, XAS_hv_all_nan, label = 'nan norm')\n",
    "#plt.legend(loc=0)\n",
    "\n",
    "# Plot the binned data\n",
    "\"\"\"\n",
    "plt.figure()\n",
    "plt.plot(E_bin_centers, I_XAS_bin_norm, label = '1d binnig')\n",
    "plt.plot(E_bin_centers, XAS_hv_all, label = '2d binnig')\n",
    "plt.legend(loc=0)\n",
    "\"\"\"\n",
    "### PLOT INCL ERRORBARS ###\n",
    "plt.figure(figsize = [8, 8])\n",
    "plt.subplot(221)\n",
    "X,Y = np.meshgrid(E_bin_edges, delays_fs_edges*1e-3)\n",
    "plt.pcolor(X, Y, XAS_2dmatrix)\n",
    "plt.xlabel('hv in (eV)')\n",
    "plt.ylabel('Delay (ps)')\n",
    "plt.ylim([np.min(delays_fs*1e-3), np.max(delays_fs*1e-3)])\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.errorbar(XAS_delay_all, delays_fs*1e-3, xerr = XAS_delay_all_err, markersize = 5, marker = 'o', ls = '-')\n",
    "plt.ylim([np.min(delays_fs*1e-3), np.max(delays_fs*1e-3)])\n",
    "#plt.ylabel('Delay stage pos (mm)')\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.errorbar(E_bin_centers, XAS_hv_all, yerr = XAS_hv_all_err, markersize = 5, marker = 'o', ls = '-')\n",
    "plt.xlim([np.min(E_bin_edges), np.max(E_bin_edges)])\n",
    "plt.xlabel('hv in (eV)')\n",
    "\n",
    "plt.suptitle('XAS vs Delay map (incl errorbars)')\n",
    "\n",
    "### PLOT WITHOUT ERRORBARS ###\n",
    "plt.figure(figsize = [8, 8])\n",
    "plt.subplot(221)\n",
    "X,Y = np.meshgrid(E_bin_edges, delays_fs_edges*1e-3)\n",
    "plt.pcolor(X, Y, XAS_2dmatrix)\n",
    "plt.xlabel('hv in (eV)')\n",
    "plt.ylabel('Delay (ps)')\n",
    "plt.ylim([np.min(delays_fs*1e-3), np.max(delays_fs*1e-3)])\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.plot(XAS_delay_all, delays_fs*1e-3, markersize = 5, marker = 'o', ls = '-')\n",
    "plt.ylim([np.min(delays_fs*1e-3), np.max(delays_fs*1e-3)])\n",
    "#plt.ylabel('Delay stage pos (mm)')\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.plot(E_bin_centers, XAS_hv_all, markersize = 5, marker = 'o', ls = '-')\n",
    "plt.xlim([np.min(E_bin_edges), np.max(E_bin_edges)])\n",
    "plt.xlabel('hv in (eV)')\n",
    "\n",
    "plt.suptitle('XAS vs Delay map (no errorbars)')\n",
    "\n",
    "### XES SPECTRA BINNING ###\n",
    "if not xes_spec_missing and bin_xes_specs:\n",
    "    \n",
    "    # Rebin the emission energy axis (still in pixels here)\n",
    "    xes_spec_length_rebin = int(np.floor(xes_spec_length/xes_rebinning))\n",
    "    end = int(xes_rebinning * xes_spec_length_rebin)\n",
    "    xes_x       = np.arange(xes_spec_length)\n",
    "    xes_x_rebin = np.sum(np.reshape(xes_x[:end], (-1, xes_rebinning)), axis = 1) / xes_rebinning\n",
    "\n",
    "    # Create matrix to bin xes spectra into\n",
    "    xes_spec_3dmatrix = np.zeros((len(delays_mm), len(E_bin_centers), xes_spec_length_rebin))\n",
    "    \n",
    "    # Split up the complete xes spectra array into single spectra\n",
    "    xes_spec_good_split = np.split(xes_spec_good, len(bunch_id_good))\n",
    "    \n",
    "    # Get bin inices for delay and photon energy axis\n",
    "    delay_pos_good_dig     = np.digitize(delay_pos_good, delays_mm_edges, right = True) - 1\n",
    "    Gauss_centers_good_dig = np.digitize(Gauss_centers_good, E_bin_edges, right = True) - 1\n",
    "    \n",
    "    # Loop over shots\n",
    "    for i in np.arange(len(xes_spec_good_split)) :\n",
    "        # Rebin xes spectra intensity\n",
    "        xes_spec_rebin = np.sum(np.reshape(xes_spec_good_split[i][:end], (-1, xes_rebinning)), axis = 1) / xes_rebinning\n",
    "        xes_spec_rebin = xes_spec_rebin / hist_shots[delay_pos_good_dig[i], Gauss_centers_good_dig[i]]\n",
    "        # Sum up the spectra for each delay and photon energy bin\n",
    "        xes_spec_3dmatrix[delay_pos_good_dig[i], Gauss_centers_good_dig[i], :] = xes_spec_3dmatrix[delay_pos_good_dig[i], Gauss_centers_good_dig[i], :] + xes_spec_rebin\n",
    "        \n",
    "    # Tranform pixels into emission energy eV\n",
    "    xes_disp_file = getDisp(BT)\n",
    "    #disp_file = data_path + 'Dispersion/' + xes_disp_file\n",
    "    disp_file = '../src/' + xes_disp_file\n",
    "    h5_disp = h5py.File(disp_file, 'r')\n",
    "    p_disp = h5_disp['p_disp'].value\n",
    "    h5_disp.close()\n",
    "    xes_x_ev = dt.pix2eV(xes_x_rebin, p_disp)\n",
    "    \n",
    "    # Get the XES spectrum for all delays and all photon energies\n",
    "    xes_spec_sum_all = np.sum(np.sum(xes_spec_3dmatrix, axis = 0), axis = 0)\n",
    "    # Sum up all photon energies\n",
    "    xes_specs_delay = np.sum(xes_spec_3dmatrix, axis = 1)\n",
    "    # Sum up all delays\n",
    "    xes_specs_hv = np.sum(xes_spec_3dmatrix, axis = 0)\n",
    "    \n",
    "    plt.figure()\n",
    "    for i in np.arange(len(E_bin_centers)) :\n",
    "        plt.plot(xes_x_ev, xes_specs_hv[i], '-o', ms = 3, label = E_bin_centers[i])\n",
    "    plt.legend(loc = 0)\n",
    "    plt.title('XES for each hv_in bin')\n",
    "    plt.xlim([260, 290])\n",
    "\n",
    "    \n",
    "### XES blobs BINNING ### (Under construction.... / Not Used)\n",
    "if not xes_missing and bin_xes_blobs:\n",
    "    # Create emission energy axis (still in pixels) and bin edges    \n",
    "    XES_bin_edges   = np.arange(0, disp_pixels, xes_rebinning)\n",
    "    XES_bin_centers = (XES_bin_edges[1:] + XES_bin_edges[:-1]) / 2\n",
    "    # Curvature correction\n",
    "    curv_file = data_path + 'Curvatures/' + xes_curv_file\n",
    "    h5_curve = h5py.File(curv_file, 'r')\n",
    "    p_curv = h5_curve['popt'].value\n",
    "    h5_curve.close()\n",
    "    \n",
    "    p1 = p_curv[0]\n",
    "    p2 = p_curv[1]\n",
    "    p3 = p_curv[2]\n",
    "    \n",
    "    xes_blobs_x_good_corr = np.zeros(np.shape(xes_blobs_x_good))\n",
    "    \n",
    "    for i in np.arange(len(xes_blobs_x_good)) :\n",
    "        shift = poly2(xes_blobs_y_good[i], p1, p2, p3) - p3\n",
    "        xes_blobs_x_good_corr[i] = xes_blobs_x_good[i] - shift\n",
    "\n",
    "    # 1. Repeat delay positions and hv_in according to number of XES blobs\n",
    "    # 2. Transform the vectors (np.newaxis command) for later concatenation\n",
    "    delay_pos_good_xes     = np.array(np.repeat(delay_pos_good, xes_blobsnum_good))[np.newaxis]\n",
    "    Gauss_centers_good_xes = np.array(np.repeat(Gauss_centers_good, xes_blobsnum_good))[np.newaxis]\n",
    "    xes_blobs_x_good       = np.array(xes_blobs_x_good_corr)[np.newaxis]\n",
    "    \n",
    "    # Concatenate delay positions, hv_in and XES blobs x-positions for 3d histogramming\n",
    "    delay_hv_xes = np.concatenate((np.transpose(delay_pos_good_xes), np.transpose(Gauss_centers_good_xes), np.transpose(xes_blobs_x_good)), axis=1)\n",
    "\n",
    "    # Do the 3d histogram\n",
    "    # H is 3d dataset delay-hv_in_hv_emission: axis 0 = delay, axis 1 = hv inc, axis 2 = hv emission\n",
    "    H, edges = np.histogramdd(delay_hv_xes, bins = (delays_mm_edges, E_bin_edges, XES_bin_edges))\n",
    "    \n",
    "    # Sum up all delays and all inc photon energies --> XES spectrum\n",
    "    XES_all = np.sum(np.sum(H, axis = 0), axis = 0)\n",
    "    # Sum up all inc photon energies --> XES spectrum\n",
    "    XES_delays_all = np.sum(H, axis = 1)\n",
    "    # Sum up all emission energies and all delays --> PFY XAS spectrum\n",
    "    XAS_PFY_hv_all = np.sum(np.sum(H, axis = 2), axis = 0)\n",
    "    # Sum up all emission energies and all incident energies --> PFY XAS delay trace\n",
    "    XAS_PFY_delay_all = np.sum(np.sum(H, axis = 2), axis = 1)\n",
    "\n",
    "#############################################\n",
    "### SAVE THE DATA AND PARAMETERS/SETTINGS ###\n",
    "#############################################\n",
    "# If 'Binned' folder does not yet exist, create it\n",
    "# if not os.path.exists(data_path+'Binned/') :\n",
    "#    os.makedirs(data_path+'Binned/')\n",
    "    \n",
    "# Define the filename for saved data\n",
    "run_s_str = '%03d'%(runs[0])\n",
    "run_e_str = '%03d'%(runs[-1])\n",
    "# save_file   = data_path+'Binned/'+run_type+'_'+run_s_str+'_'+run_e_str+'_bin.h5'\n",
    "save_file = 'C:/Users/larue/OneDrive - Chapman University/Research/X-Ray Femtochemistry/Fermi 2017/Binned/BT'+str(BT)+'/'+run_type+'_'+run_s_str+'_'+run_e_str+'_bin.h5'            \n",
    "\n",
    "# Open file (if exists), else create file\n",
    "fh5 = h5py.File(save_file, 'a') \n",
    "\n",
    "# Runs\n",
    "if 'runs' in fh5: del fh5['runs']\n",
    "dataSet = fh5.create_dataset('runs', data = runs, dtype = np.int32)\n",
    "# TimeZero\n",
    "if 'TimeZero' in fh5: del fh5['TimeZero']\n",
    "dataSet = fh5.create_dataset('TimeZero', data = TimeZero, dtype = np.float32)\n",
    "\n",
    "# XAS source\n",
    "if 'XAS_source' in fh5: del fh5['XAS_source']\n",
    "dataSet = fh5.create_dataset('XAS_source', data = np.string_(XAS_source), dtype=\"S10\")\n",
    "\n",
    "### Filter Settings\n",
    "# filter_i0\n",
    "if 'FilterSettings/filter_i0' in fh5: del fh5['FilterSettings/filter_i0']\n",
    "dataSet = fh5.create_dataset('FilterSettings/filter_i0', data = filter_i0, dtype = 'u1')\n",
    "# i0_low_thr\n",
    "if 'FilterSettings/i0_low_thr' in fh5: del fh5['FilterSettings/i0_low_thr']\n",
    "dataSet = fh5.create_dataset('FilterSettings/i0_low_thr', data = i0_low_thr, dtype = np.float32)\n",
    "# i0_hi_thr\n",
    "if 'FilterSettings/i0_hi_thr' in fh5: del fh5['FilterSettings/i0_hi_thr']\n",
    "dataSet = fh5.create_dataset('FilterSettings/i0_hi_thr', data = i0_hi_thr, dtype = np.float32)\n",
    "\n",
    "# filter_width\n",
    "if 'FilterSettings/filter_width' in fh5: del fh5['FilterSettings/filter_width']\n",
    "dataSet = fh5.create_dataset('FilterSettings/filter_width', data = filter_width, dtype = 'u1')\n",
    "# width_low_thr\n",
    "if 'FilterSettings/width_low_thr' in fh5: del fh5['FilterSettings/width_low_thr']\n",
    "dataSet = fh5.create_dataset('FilterSettings/width_low_thr', data = width_low_thr, dtype = np.float32)\n",
    "# i0_hi_thr\n",
    "if 'FilterSettings/width_hi_thr' in fh5: del fh5['FilterSettings/width_hi_thr']\n",
    "dataSet = fh5.create_dataset('FilterSettings/width_hi_thr', data = width_hi_thr, dtype = np.float32)\n",
    "\n",
    "# filter_ms\n",
    "if 'FilterSettings/filter_ms' in fh5: del fh5['FilterSettings/filter_ms']\n",
    "dataSet = fh5.create_dataset('FilterSettings/filter_ms', data = filter_ms, dtype = 'u1')\n",
    "# ms_low_thr\n",
    "if 'FilterSettings/ms_low_thr' in fh5: del fh5['FilterSettings/ms_low_thr']\n",
    "dataSet = fh5.create_dataset('FilterSettings/ms_low_thr', data = ms_low_thr, dtype = np.float32)\n",
    "# i0_hi_thr\n",
    "if 'FilterSettings/ms_hi_thr' in fh5: del fh5['FilterSettings/ms_hi_thr']\n",
    "dataSet = fh5.create_dataset('FilterSettings/ms_hi_thr', data = ms_hi_thr, dtype = np.float32)\n",
    "\n",
    "### Bin Settings\n",
    "# XAS E_bin_type\n",
    "if 'BinSettings/E_bin_type' in fh5: del fh5['BinSettings/E_bin_type']\n",
    "dataSet = fh5.create_dataset('BinSettings/E_bin_type', data = np.string_(E_bin_type), dtype=\"S10\")\n",
    "if E_bin_type == 'auto' :\n",
    "    # E_bin_width\n",
    "    if 'BinSettings/E_bin_width' in fh5: del fh5['BinSettings/E_bin_width']\n",
    "    dataSet = fh5.create_dataset('BinSettings/E_bin_width', data = E_bin_width, dtype = np.float32)\n",
    "if E_bin_type == 'manual' :\n",
    "    # E_bin_edges_man\n",
    "    if 'BinSettings/E_bin_edges_man' in fh5: del fh5['BinSettings/E_bin_edges_man']\n",
    "    dataSet = fh5.create_dataset('BinSettings/E_bin_edges_man', data = E_bin_edges_man, dtype = np.float32)\n",
    "    \n",
    "# Delay Bintype\n",
    "if 'BinSettings/delay_bin_type' in fh5: del fh5['BinSettings/delay_bin_type']\n",
    "dataSet = fh5.create_dataset('BinSettings/delay_bin_type', data = np.string_(delay_bin_type), dtype=\"S10\")\n",
    "if delay_bin_type == 'manual' :\n",
    "    # delay_bin_edges_unit\n",
    "    if 'BinSettings/delay_bin_unit' in fh5: del fh5['BinSettings/delay_bin_unit']\n",
    "    dataSet = fh5.create_dataset('BinSettings/delay_bin_unit', data = np.string_(delay_bin_unit), dtype=\"S10\")\n",
    "    # delay_bin_edges_man\n",
    "    if 'BinSettings/delays_edges_man' in fh5: del fh5['BinSettings/delays_edges_man']\n",
    "    dataSet = fh5.create_dataset('BinSettings/delays_edges_man', data = delays_edges_man, dtype = np.float32)\n",
    "    \n",
    "if not xes_spec_missing :\n",
    "    # XES emissino energy axis rebinning\n",
    "    if 'BinSettings/xes_rebinning' in fh5: del fh5['BinSettings/xes_rebinning']\n",
    "    dataSet = fh5.create_dataset('BinSettings/xes_rebinning', data = xes_rebinning, dtype = np.int32)\n",
    "\n",
    "### Binned Data\n",
    "# Incident photon energy axis\n",
    "if 'BinnedData/E_bin_centers' in fh5: del fh5['BinnedData/E_bin_centers']\n",
    "dataSet = fh5.create_dataset('BinnedData/E_bin_centers', data = E_bin_centers, dtype = np.float32)\n",
    "if 'BinnedData/E_bin_edges' in fh5: del fh5['BinnedData/E_bin_edges']\n",
    "dataSet = fh5.create_dataset('BinnedData/E_bin_edges', data = E_bin_edges, dtype = np.float32)\n",
    "\n",
    "# Delay axis in mm\n",
    "if 'BinnedData/delays_mm' in fh5: del fh5['BinnedData/delays_mm']\n",
    "dataSet = fh5.create_dataset('BinnedData/delays_mm', data = delays_mm, dtype = np.float32)\n",
    "if 'BinnedData/delays_mm_edges' in fh5: del fh5['BinnedData/delays_mm_edges']\n",
    "dataSet = fh5.create_dataset('BinnedData/delays_mm_edges', data = delays_mm_edges, dtype = np.float32)\n",
    "# Delay axis in fs\n",
    "if 'BinnedData/delays_fs' in fh5: del fh5['BinnedData/delays_fs']\n",
    "dataSet = fh5.create_dataset('BinnedData/delays_fs', data = delays_fs, dtype = np.float32)\n",
    "if 'BinnedData/delays_fs_edges' in fh5: del fh5['BinnedData/delays_fs_edges']\n",
    "dataSet = fh5.create_dataset('BinnedData/delays_fs_edges', data = delays_fs_edges, dtype = np.float32)\n",
    "\n",
    "# 2D data\n",
    "# XAS intensity 2d matrix\n",
    "if 'BinnedData/XAS_2dmatrix' in fh5: del fh5['BinnedData/XAS_2dmatrix']\n",
    "dataSet = fh5.create_dataset('BinnedData/XAS_2dmatrix', data = XAS_2dmatrix, dtype = np.float32)\n",
    "# XAS intensity 2d matrix (v2 - calculated as hist_tfy/hist_i0)\n",
    "if 'BinnedData/XAS_2dmatrix_v2' in fh5: del fh5['BinnedData/XAS_2dmatrix_v2']\n",
    "dataSet = fh5.create_dataset('BinnedData/XAS_2dmatrix_v2', data = XAS_2dmatrix_v2, dtype = np.float32)\n",
    "# Shots 2d matrix\n",
    "if 'BinnedData/Shots_2dmatrix' in fh5: del fh5['BinnedData/Shots_2dmatrix']\n",
    "dataSet = fh5.create_dataset('BinnedData/Shots_2dmatrix', data = Shots_2dmatrix, dtype = np.float32)\n",
    "# I0 2d matrix (I0 intensity per shot)\n",
    "if 'BinnedData/i0_2dmatrix' in fh5: del fh5['BinnedData/i0_2dmatrix']\n",
    "dataSet = fh5.create_dataset('BinnedData/i0_2dmatrix', data = i0_2dmatrix, dtype = np.float32)\n",
    "# TFY 2d matrix (XAS detector intensity per shot - not normalized by I0)\n",
    "if 'BinnedData/TFY_2dmatrix' in fh5: del fh5['BinnedData/TFY_2dmatrix']\n",
    "dataSet = fh5.create_dataset('BinnedData/TFY_2dmatrix', data = TFY_2dmatrix, dtype = np.float32)\n",
    "\n",
    "# ERRORS 2D data\n",
    "# XAS intensity 2d matrix\n",
    "if 'BinnedData/XAS_2dmatrix_err' in fh5: del fh5['BinnedData/XAS_2dmatrix_err']\n",
    "dataSet = fh5.create_dataset('BinnedData/XAS_2dmatrix_err', data = XAS_2dmatrix_err, dtype = np.float32)\n",
    "# I0 2d matrix\n",
    "if 'BinnedData/i0_2dmatrix_err' in fh5: del fh5['BinnedData/i0_2dmatrix_err']\n",
    "dataSet = fh5.create_dataset('BinnedData/i0_2dmatrix_err', data = i0_2dmatrix_err, dtype = np.float32)\n",
    "# TFY 2d matrix (XAS detector intensity - not normalized by I0 nor by number of shots)\n",
    "if 'BinnedData/TFY_2dmatrix_err' in fh5: del fh5['BinnedData/TFY_2dmatrix_err']\n",
    "dataSet = fh5.create_dataset('BinnedData/TFY_2dmatrix_err', data = TFY_2dmatrix_err, dtype = np.float32)\n",
    "\n",
    "# PROJECTIONS\n",
    "# XAS spectrum\n",
    "if 'BinnedData/XAS_hv_all' in fh5: del fh5['BinnedData/XAS_hv_all']\n",
    "dataSet = fh5.create_dataset('BinnedData/XAS_hv_all', data = XAS_hv_all, dtype = np.float32)\n",
    "# Delay trace\n",
    "if 'BinnedData/XAS_delay_all' in fh5: del fh5['BinnedData/XAS_delay_all']\n",
    "dataSet = fh5.create_dataset('BinnedData/XAS_delay_all', data = XAS_delay_all, dtype = np.float32)\n",
    "\n",
    "# ERRORS PROJECTIONS \n",
    "# XAS spectrum\n",
    "if 'BinnedData/XAS_hv_all_err' in fh5: del fh5['BinnedData/XAS_hv_all_err']\n",
    "dataSet = fh5.create_dataset('BinnedData/XAS_hv_all_err', data = XAS_hv_all_err, dtype = np.float32)\n",
    "# Delay trace\n",
    "if 'BinnedData/XAS_delay_all_err' in fh5: del fh5['BinnedData/XAS_delay_all_err']\n",
    "dataSet = fh5.create_dataset('BinnedData/XAS_delay_all_err', data = XAS_delay_all_err, dtype = np.float32)\n",
    "\n",
    "# XES BINNED DATA\n",
    "if not xes_spec_missing and bin_xes_specs:\n",
    "    # XES emission energy axis in pixels\n",
    "    if 'BinnedData/xes_x_pix' in fh5: del fh5['BinnedData/xes_x_pix']\n",
    "    dataSet = fh5.create_dataset('BinnedData/xes_x_pix', data = xes_x_rebin, dtype = np.float32)\n",
    "    # XES emission energy axis in eV\n",
    "    if 'BinnedData/xes_x_ev' in fh5: del fh5['BinnedData/xes_x_ev']\n",
    "    dataSet = fh5.create_dataset('BinnedData/xes_x_ev', data = xes_x_ev, dtype = np.float32)\n",
    "    # 3d dataset (2d matrix in photon energy and delay with full emission spectrum for each bin)\n",
    "    if 'BinnedData/xes_spec_3dmatrix' in fh5: del fh5['BinnedData/xes_spec_3dmatrix']\n",
    "    dataSet = fh5.create_dataset('BinnedData/xes_spec_3dmatrix', data = xes_spec_3dmatrix, dtype = np.float32)\n",
    "    # XES spectrum summed together for all delays and all photon energies\n",
    "    if 'BinnedData/xes_spec_sum_all' in fh5: del fh5['BinnedData/xes_spec_sum_all']\n",
    "    dataSet = fh5.create_dataset('BinnedData/xes_spec_sum_all', data = xes_spec_sum_all, dtype = np.float32)\n",
    "\n",
    "fh5.close() # Close the file\n",
    "print('Saved file '+save_file)\n",
    "\n",
    "print('\\nDONE!')\n",
    "print('Total time in sec:')\n",
    "print(time.time() - t)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If having problems with open HDF5 files, run below lines to close all HDF5 files that are still open\n",
    "\n",
    "#### This can happen when e.g. the script crashes and files stay open."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'functools._lru_list_elem' object has no attribute '__class__'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-226bd789da94>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_objects\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m   \u001b[1;31m# Browse through ALL objects\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m   \u001b[1;31m# Just HDF5 files\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Closed %s.'\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\abc.py\u001b[0m in \u001b[0;36m__instancecheck__\u001b[1;34m(cls, instance)\u001b[0m\n\u001b[0;32m    179\u001b[0m         \u001b[1;34m\"\"\"Override for isinstance(instance, cls).\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m         \u001b[1;31m# Inline the cache checking\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m         \u001b[0msubclass\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minstance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msubclass\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_abc_cache\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'functools._lru_list_elem' object has no attribute '__class__'"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "for obj in gc.get_objects():   # Browse through ALL objects\n",
    "    if isinstance(obj, h5py.File):   # Just HDF5 files\n",
    "        try:\n",
    "            print('Closed %s.'%obj.filename)\n",
    "            obj.close()\n",
    "        except:\n",
    "            pass # Was already closed\n",
    "print('Done!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
